{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQsSAsgpfJp6"
      },
      "source": [
        "**Run these cells for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLCy9ULSeV-b",
        "outputId": "8644e71e-6110-419d-e444-9ea4fa3ae12a"
      },
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Requirement already satisfied: torch_nightly in /usr/local/lib/python3.6/dist-packages (1.2.0.dev20190805+cu92)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.8.0)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.5)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (50.3.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.4)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4->fastai) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lfo3cYbe0RH",
        "outputId": "7145dc39-739c-4f76-ed9a-264a9775a400"
      },
      "source": [
        "!apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr \\\n",
        "flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig libpulse-dev"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "antiword is already the newest version (0.37-11build1).\n",
            "flac is already the newest version (1.3.2-1).\n",
            "lame is already the newest version (3.100-2).\n",
            "pstotext is already the newest version (1.9-6build1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "unrtf is already the newest version (0.21.9-clean-3).\n",
            "libpulse-dev is already the newest version (1:11.1-1ubuntu7.11).\n",
            "libxml2-dev is already the newest version (2.9.4+dfsg1-6.1ubuntu1.3).\n",
            "libxslt1-dev is already the newest version (1.1.29-5ubuntu0.2).\n",
            "poppler-utils is already the newest version (0.62.0-2ubuntu2.12).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libmad0 is already the newest version (0.15.1b-9ubuntu18.04.1).\n",
            "libsox-fmt-mp3 is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "sox is already the newest version (14.4.2-3ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PImMeOLnfD6X",
        "outputId": "b9e45733-f0d2-43fc-d0bc-8f63e9c97dfe"
      },
      "source": [
        "!pip install text-preprocessing\n",
        "!pip install textract\n",
        "!pip install azure-storage-blob"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: text-preprocessing in /usr/local/lib/python3.6/dist-packages (0.0.9)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (from text-preprocessing) (0.0.43)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (from text-preprocessing) (0.5.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from text-preprocessing) (3.2.5)\n",
            "Requirement already satisfied: names-dataset in /usr/local/lib/python3.6/dist-packages (from text-preprocessing) (1.9.1)\n",
            "Requirement already satisfied: unittest-xml-reporting in /usr/local/lib/python3.6/dist-packages (from text-preprocessing) (3.0.4)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions->text-preprocessing) (0.0.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->text-preprocessing) (1.12.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions->text-preprocessing) (1.4.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions->text-preprocessing) (1.1.1)\n",
            "Requirement already satisfied: textract in /usr/local/lib/python3.6/dist-packages (1.6.3)\n",
            "Requirement already satisfied: SpeechRecognition==3.8.1 in /usr/local/lib/python3.6/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: EbookLib==0.17.1 in /usr/local/lib/python3.6/dist-packages (from textract) (0.17.1)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: python-pptx==0.6.18 in /usr/local/lib/python3.6/dist-packages (from textract) (0.6.18)\n",
            "Requirement already satisfied: xlrd==1.2.0 in /usr/local/lib/python3.6/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: argcomplete==1.10.0 in /usr/local/lib/python3.6/dist-packages (from textract) (1.10.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.8.0 in /usr/local/lib/python3.6/dist-packages (from textract) (4.8.0)\n",
            "Requirement already satisfied: docx2txt==0.8 in /usr/local/lib/python3.6/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: pdfminer.six==20181108 in /usr/local/lib/python3.6/dist-packages (from textract) (20181108)\n",
            "Requirement already satisfied: extract-msg==0.23.1 in /usr/local/lib/python3.6/dist-packages (from textract) (0.23.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from EbookLib==0.17.1->textract) (4.2.6)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.6/dist-packages (from python-pptx==0.6.18->textract) (1.3.7)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from python-pptx==0.6.18->textract) (7.0.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4==4.8.0->textract) (2.0.1)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.6/dist-packages (from pdfminer.six==20181108->textract) (3.9.9)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdfminer.six==20181108->textract) (2.3.0)\n",
            "Requirement already satisfied: tzlocal==1.5.1 in /usr/local/lib/python3.6/dist-packages (from extract-msg==0.23.1->textract) (1.5.1)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.6/dist-packages (from extract-msg==0.23.1->textract) (2.1.0)\n",
            "Requirement already satisfied: olefile==0.46 in /usr/local/lib/python3.6/dist-packages (from extract-msg==0.23.1->textract) (0.46)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tzlocal==1.5.1->extract-msg==0.23.1->textract) (2018.9)\n",
            "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.6/dist-packages (12.6.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob) (1.9.0)\n",
            "Requirement already satisfied: msrest>=0.6.10 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob) (0.6.19)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob) (3.2.1)\n",
            "Requirement already satisfied: six>=1.6 in /usr/local/lib/python3.6/dist-packages (from azure-core<2.0.0,>=1.9.0->azure-storage-blob) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from azure-core<2.0.0,>=1.9.0->azure-storage-blob) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.10->azure-storage-blob) (2020.11.8)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.14.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.9.0->azure-storage-blob) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.9.0->azure-storage-blob) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.9.0->azure-storage-blob) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-storage-blob) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-storage-blob) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EAwJekfQH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adae350e-ab7b-49ff-ef13-ab4b8c6dd94f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords', quiet = True)\n",
        "nltk.download('punkt', quiet = True)\n",
        "nltk.download('words',quiet = True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZsfQAv9gNAT"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oin4NmhGgTA6"
      },
      "source": [
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from text_preprocessing import preprocess_text\n",
        "import textract\n",
        "from functools import partial\n",
        "import re\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ESrhkerhIoZ"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSSbSok6g-zV"
      },
      "source": [
        "rootdir = 'Specify the path of root directory here'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF0Qm9YCgPgS"
      },
      "source": [
        "def unique_list(l):\n",
        "    ulist = []\n",
        "    [ulist.append(x) for x in l if x not in ulist]\n",
        "    return ulist"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoBjtrd_ggw4"
      },
      "source": [
        "def process(rootdir, train = True):\n",
        "  #File path.\n",
        "  paths = []\n",
        "  #File name. \n",
        "  fname = []\n",
        "  #Textracted content from file.\n",
        "  descr = []\n",
        "  #Labels of file.\n",
        "  label = []\n",
        "  #Length of each document.\n",
        "  length = []\n",
        "  # Store the list of stop words in english language.\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  # Store the list of words common in english language.  \n",
        "  words = set(nltk.corpus.words.words())\n",
        "\n",
        "  # Walking through folders & subfolders in the root directory.\n",
        "  for subdir, dirs, files in os.walk(rootdir):\n",
        "    extract_label = subdir.split('/')\n",
        "    for file in files:\n",
        "        # Append the path of the file to path variable.\n",
        "        paths.append(os.path.join(subdir, file))\n",
        "        # Append the filename to the filename variable.\n",
        "        fname.append(str(file))\n",
        "        # Append the label to label variable.\n",
        "        label.append(int(extract_label[-1])) #[Optional May Change Depending on your folder structure].\n",
        "\n",
        "        # Extract the text from the files and decode the byte string to text.\n",
        "        text = textract.process(os.path.join(subdir, file)).decode(\"utf-8\") \n",
        "        \n",
        "        # Preprocess the text with a custom library. (Includes stemming, lemmatization, removal of special characters).\n",
        "        t = preprocess_text(text)\n",
        "  \n",
        "        # Tokenize the text.\n",
        "        word_tokens = word_tokenize(t)  \n",
        "  \n",
        "        # Apply a filter to the text which removes stop words.\n",
        "        filtered_sentence = [w for w in word_tokens if w not in stop_words]  \n",
        "        \n",
        "        # Remove charcaters which are not properly processed in the text.\n",
        "        filtered_sentence = [w for w in filtered_sentence if len(w) > 3]\n",
        "\n",
        "        # Remove any numeric characters that got included in text\n",
        "        filtered_sentence = [''.join(x for x in i if x.isalpha()) for i in filtered_sentence]\n",
        "\n",
        "        # Join the tokens with space(' ') as delimiter.\n",
        "        filtered_sentence = \" \".join(filtered_sentence)\n",
        "\n",
        "        # Remove extra spaces in the text.\n",
        "        res = re.sub(' +', ' ', filtered_sentence) \n",
        "\n",
        "        # Join the text.\n",
        "        a=' '.join(unique_list(res.split()))\n",
        "\n",
        "        # Remove the words that are not present in english language.\n",
        "        a = \" \".join(w for w in nltk.wordpunct_tokenize(a) \\\n",
        "              if w.lower() in words or not w.isalpha())\n",
        "        \n",
        "        # Append the text to description variable.\n",
        "        descr.append(a)\n",
        "\n",
        "        # Append the length of text to length variable.\n",
        "        length.append(len(a))\n",
        "    \n",
        "  if train:\n",
        "    # Converting the target variable to a numpy array.\n",
        "    label = np.array(label)\n",
        "  \n",
        "  return {\"FileName\" : fname, \"FilePath\" : paths, \"Text\" : descr ,\"Label\" : label, \"Length\" : length}\n",
        "\n",
        "def saveandsplit(Data_Frame):\n",
        "  # Dropping NaN values.\n",
        "  Data_Frame['Text'].isnull().sum()\n",
        "  Data_Frame.dropna(inplace = True)\n",
        "\n",
        "  # Saving the dataset to a csv for future use. [OPTIONAL STEP]\n",
        "  Data_Frame.to_csv('Dataset.csv', encoding='utf-8', index = False)\n",
        "\n",
        "  # Remove column names 'FileName' & 'FilePath from Dataframe for training. \n",
        "  Data_Frame.drop(['FileName', 'FilePath', 'Length'], axis = 1, inplace = True)\n",
        "\n",
        "  # split data into training and validation set\n",
        "  DataFrame_Train, DataFrame_Val = train_test_split(Data_Frame, stratify = Data_Frame['Label'], test_size = 0.2, random_state = 100)\n",
        "\n",
        "  #reseting index for test_data\n",
        "  DataFrame_Val.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  #resting index for train_data\n",
        "  DataFrame_Train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  return DataFrame_Train, DataFrame_Val\n",
        "\n",
        "def prepareData(DataFrame_Train, DataFrame_Val):\n",
        "  # Language model data\n",
        "  data_lm = (TextList.from_df(df=DataFrame_Train, cols=['Text', 'Label']).split_by_rand_pct(0.2).label_for_lm().databunch(bs=4, bptt=80, num_workers=0))\n",
        "\n",
        "  # Classifier model data\n",
        "  data_clas = TextClasDataBunch.from_df(\".\", train_df=DataFrame_Train,valid_df=DataFrame_Val, vocab=data_lm.train_ds.vocab, text_cols='Text', label_cols='Label',bs=2)\n",
        "\n",
        "  return data_lm, data_clas"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjLTk1O-gqTZ"
      },
      "source": [
        "Data        = process(rootdir)\n",
        "Data_Frame  = pd.DataFrame(Data, columns = ['FileName', 'FilePath', 'Text' ,'Label', 'Length'])\n",
        "DataFrame_Train, DataFrame_Val = saveandsplit(Data_Frame)\n",
        "data_lm, data_clas = prepareData(DataFrame_Train, DataFrame_Val)\n",
        "\n",
        "learn = language_model_learner(data_lm, arch = AWD_LSTM, pretrained = True, drop_mult=0.4)\n",
        "learn.fit_one_cycle(1, 1e-2)\n",
        "#learn.save('stage-1')\n",
        "\n",
        "# Save this encoder to use it for classification later\n",
        "learn.save_encoder('ft_enc')\n",
        "\n",
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.4)\n",
        "learn.load_encoder('ft_enc')\n",
        "\n",
        "learn.lr_find()\n",
        "learn.recorder.plot()\n",
        "\n",
        "# Fit again the model\n",
        "learn.fit_one_cycle(2, 1e-1)\n",
        "#learn.save('stage-2a')\n",
        "\n",
        "# Export pkl file.\n",
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}